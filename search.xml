<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>天池机器学习实战笔记总结</title>
      <link href="/2023/05/17/tianchi-ML/"/>
      <url>/2023/05/17/tianchi-ML/</url>
      
        <content type="html"><![CDATA[<h1 id="本文仅限天才可爱的咕咕鸟阅读"><a href="#本文仅限天才可爱的咕咕鸟阅读" class="headerlink" title="本文仅限天才可爱的咕咕鸟阅读"></a>本文仅限<strong>天才可爱的咕咕鸟</strong>阅读</h1><h2 id="本文包含内容"><a href="#本文包含内容" class="headerlink" title="本文包含内容"></a>本文包含内容</h2><p>一、数据探索<br>二、特征工程<br>三、模型训练<br>四、模型验证<br>五、特征优化<br>六、模型融合<br>七、代码的规范和技巧<br>八、参考文献</p><span id="more"></span><h2 id="一、数据探索"><a href="#一、数据探索" class="headerlink" title="一、数据探索"></a>一、数据探索</h2><h3 id="1、识别变量（查看数据大小和数据类型）"><a href="#1、识别变量（查看数据大小和数据类型）" class="headerlink" title="1、识别变量（查看数据大小和数据类型）"></a>1、识别变量（查看数据大小和数据类型）</h3><ul><li>1.1 识别输入变量和输出变量：查看哪些是<strong>输入变量</strong>哪些是<strong>输出变量</strong></li><li>1.2 识别数据类型：数据类型分为<strong>数值型</strong>和<strong>字符型</strong></li><li>1.3 识别<strong>连续型变量</strong>和<strong>类别型变量</strong></li></ul><h3 id="2、变量分析"><a href="#2、变量分析" class="headerlink" title="2、变量分析"></a>2、变量分析</h3><ul><li><p>2.1 单变量分析</p><ul><li><p>2.1.1 连续型变量：需要统计数据的中心分布趋势和变量的分布</p><table><thead><tr><th align="left">中心分布趋势</th><th align="center">离差测量</th><th align="right">可视化</th></tr></thead><tbody><tr><td align="left">mean</td><td align="center">range</td><td align="right">频率分布直方图(histogram)</td></tr><tr><td align="left">median</td><td align="center">quartile</td><td align="right">箱线图(box plot)</td></tr><tr><td align="left">mode(众数)</td><td align="center">IQR</td><td align="right">核密度估计分布图（KED）</td></tr><tr><td align="left">min</td><td align="center">Variance</td><td align="right">Q-Q图</td></tr><tr><td align="left">max</td><td align="center">Standard Deviation</td><td align="right"></td></tr><tr><td align="left"></td><td align="center"></td><td align="right">Skewness(偏态) and Kurtosi(峰度)</td></tr></tbody></table></li><li><p>2.1.2 类别型变量<br>  一般使用频次或占比表示每一个类别的分布情况，对应的衡量指标分别是类别变量的频次和频率（占比），可以用柱形图可视化</p></li></ul></li><li><p>2.2 双变量分析(发现变量间的关系)</p><ul><li><p>2.2.1 连续和连续</p><table><thead><tr><th align="left">方法</th><th align="center">绘制散点图</th><th align="right">计算相关性</th></tr></thead><tbody><tr><td align="left">目的</td><td align="center">反应是否为线性相关关系（直观看出变量间的关系）</td><td align="right">定量计算变量间的关系（之后可利用相关性进行特征筛选）</td></tr><tr><td align="left">可视化</td><td align="center">线性回归关系图</td><td align="right">绘制相关性热力图</td></tr></tbody></table></li><li><p>2.2.2 连续和类别</p><ul><li>小提琴图P9（分析类别变量在不同类别是，另一个连续变量的分布情况）</li></ul></li><li><p>2.2.3 类别和类别</p><ul><li><p>双向表</p></li><li><p>堆叠柱状图P9</p><ul><li>比双向表直观</li></ul></li><li><p>卡方检验</p><ul><li>主要用于两个和两个以上样本率（构成比）及两个二值型变量的关联性分析，即比较理论频次与实际频次的吻合程度或拟合优度</li></ul></li></ul></li></ul></li><li><p>2.3 常见的数据分布</p><ul><li>伯努利分布</li><li>泊松分布</li><li>几何分布</li><li>正态分布</li><li>二项分布</li><li>指数分布</li></ul></li><li><p>2.4 多重共线性分析</p></li></ul><h3 id="3、判断样本是否均衡"><a href="#3、判断样本是否均衡" class="headerlink" title="3、判断样本是否均衡"></a>3、判断样本是否均衡</h3><h3 id="4、缺失值探索"><a href="#4、缺失值探索" class="headerlink" title="4、缺失值探索"></a>4、缺失值探索</h3><ul><li><p>缺失值检测</p><ul><li><p>可以使用pandas的count()（计算不为空的数据个数）及shape()（统计样本个数）进行统计，计算缺失率等</p></li><li><p>隐藏缺失值</p><ul><li>需要理解数据集的含义可能有的情况下0代表缺失值</li></ul></li></ul></li><li><p>缺失值产生的原因和分类</p><ul><li>完全随机丢失</li><li>随机丢失</li><li>不可预测因子导致的丢失</li><li>取决于自身的缺失</li></ul></li></ul><h3 id="5、异常值探索"><a href="#5、异常值探索" class="headerlink" title="5、异常值探索"></a>5、异常值探索</h3><ul><li><p>异常值检测</p><ul><li>箱线图</li><li>直方图</li><li>散点图</li></ul></li><li><p>异常值产生的原因及分类</p><ul><li>数据输入误差</li><li>测量误差</li><li>实验误差</li><li>有意造成的异常值</li><li>数据处理误差</li><li>采样误差</li></ul></li><li><p>异常值的影响P12</p></li></ul><h3 id="6、变量转换"><a href="#6、变量转换" class="headerlink" title="6、变量转换"></a>6、变量转换</h3><ul><li><p>目的</p><ul><li>使变量的分布趋于想要的，有利于一些模型的拟合（如基于正态分布假设前提的模型）</li></ul></li><li><p>方法</p><ul><li>缩放比例或标准化</li><li>非线性转化为线性</li><li>使倾斜分布对称</li><li>变量分组</li><li>对数变换</li><li>平方根或立方根</li><li>Box-Cox变换P29</li></ul></li></ul><h3 id="7、新变量的生成"><a href="#7、新变量的生成" class="headerlink" title="7、新变量的生成"></a>7、新变量的生成</h3><ul><li><p>目的</p></li><li><p>方法</p><ul><li>创建派生变量</li><li>生成哑变量</li></ul></li></ul><h2 id="二、特征工程"><a href="#二、特征工程" class="headerlink" title="二、特征工程"></a>二、特征工程</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><ul><li><p>缺失值处理P38</p><ul><li><p>删除</p><ul><li>成列删除</li><li>成对删除</li></ul></li><li><p>填充</p><ul><li>平均值、众数、中值填充</li><li>预测模型填充</li><li>Em插补</li><li>多重插补MCMC</li></ul></li><li><p>不处理</p><ul><li>有的模型对缺失值不敏感算法本身有一套缺失值处理方法（如XGboost和LGB)</li></ul></li><li><p>pandas中处理缺失值的函数P137</p><ul><li>dropna</li><li>fillna</li><li>isnull</li><li>notnull</li></ul></li></ul></li><li><p>异常值处理P13</p><ul><li>删除</li><li>转换</li><li>填充</li><li>区别对待</li></ul></li><li><p>数据采样（不平衡数据）P39</p><ul><li>随机欠采样</li><li>随机过采样</li><li>基于聚类的过采样方法</li><li>SMOTE算法</li><li>基于数据清洗的SMOTE</li></ul></li></ul><h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><ul><li><p>标准化与归一化等处理P35-38（注意各方法的功能特点和限制等）</p><ul><li><p>StandardScaler</p></li><li><p>MinMaxScaler</p></li><li><p>Normalizer</p></li><li><p>数据转换</p><ul><li>多项式，指数，对数转换</li></ul></li><li><p>定量特征二值化</p></li></ul></li><li><p>类别型特征的转换</p><ul><li>序号编码</li><li>独热编码</li><li>二进制编码</li></ul></li><li><p>文本表示模型</p><ul><li><p>词袋模型</p><ul><li>TF-IDF</li></ul></li><li><p>N-gram</p></li><li><p>主题模型</p></li><li><p>词嵌入</p></li></ul></li></ul><h3 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h3><ul><li><p>特征选择</p><ul><li><p>定义与目标P39</p></li><li><p>方法</p><ul><li><p>Filter （按照发散性或者相关性对各个特征进行评分，通过设定阈值或者待选择阈值个数来选择特征）</p><ul><li>思路：特征变量和目标变量之间的关系</li><li>相关系数</li><li>卡方检验</li><li>信息增益、互信息</li></ul></li><li><p>Wrapper（根据目标函数（通常是预测效果评分）每次选择若干特征，或者排除若干特征）</p><ul><li><p>思路：通过目标函数（AUC&#x2F;MSE）来决定是否加入一个变量</p></li><li><p>迭代：产生特征子集，评价</p><ul><li><p>完全搜索</p></li><li><p>启发搜索</p></li><li><p>随机搜索</p><ul><li>遗传算法</li><li>模拟退火算法</li></ul></li></ul></li></ul></li><li><p>Embedded（使用机器学习的某些算法和模型进行训练，得到各个特征的权值系数，并根据系数从大到小选择特征）</p><ul><li><p>思路：学习期自身自动选择特征</p></li><li><p>正则化</p><ul><li>L1：LASSO、L2：RIDGE</li></ul></li><li><p>决策树</p><ul><li>熵、信息增益</li></ul></li><li><p>深度学习</p></li></ul></li></ul></li><li><p>具体实现P40</p><ul><li><p>方差选择法（Filter）</p><ul><li>VarianceThreshold</li></ul></li><li><p>可选相关系数，卡方检验最大信息系数作为得分的计算方法（Filter）</p><ul><li>SelectKBest</li></ul></li><li><p>递归消除特征法(Wrapper)</p><ul><li>RFE</li></ul></li><li><p>基于模型的特征选择法(Embedded)</p><ul><li>SelectFromModel</li></ul></li></ul></li></ul></li><li><p>线性降维</p><ul><li>多重共线性分析</li><li>PCA</li><li>LDA</li></ul></li><li><p>高维组合特征的处理P156</p><ul><li>组合特征</li><li>SVD降维</li></ul></li><li><p>组合特征P157</p><ul><li>决策树组合特征</li></ul></li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li>CountVector和TF-IDF提取特征</li><li>嵌入特征</li><li>Stacking分类特征</li><li>注意穿越特征</li></ul><h2 id="三、模型训练"><a href="#三、模型训练" class="headerlink" title="三、模型训练"></a>三、模型训练</h2><h3 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h3><ul><li><p>线性回归</p></li><li><p>多元线性回归</p></li><li><p>K近邻回归</p></li><li><p>决策树回归</p></li><li><p>集成学习回归模型</p><ul><li>随机森林回归模型</li><li>LightGBM回归模型</li></ul></li><li><p>SVR（Support Vector Regression）</p></li><li><p>弹性网络回归（利用正则化）</p><ul><li>岭回归</li><li>Lasso回归</li></ul></li><li><p>其它</p></li></ul><h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul><li><p>逻辑回归分类模型</p></li><li><p>K近邻分类模型</p></li><li><p>决策树分类模型</p></li><li><p>集成学习分类模型</p><ul><li>Bagging</li><li>Boosting</li><li>集成学习投票法</li><li>随机森林</li><li>LightGBM</li><li>极端随机树（Extra Tree,ET）</li></ul></li></ul><h2 id="四、模型验证"><a href="#四、模型验证" class="headerlink" title="四、模型验证"></a>四、模型验证</h2><h3 id="模型评估的概念和方法"><a href="#模型评估的概念和方法" class="headerlink" title="模型评估的概念和方法"></a>模型评估的概念和方法</h3><ul><li><p>评估指标</p><ul><li><p>回归</p><ul><li>Mean Absolute Error(MAE)</li><li>Mean Square Error(MSE)</li><li>Root-Mean-Square Error(RMSE)</li><li>R-Squared(R2)</li></ul></li><li><p>分类</p><ul><li><p>AUC（Area Under Curve）</p><ul><li><a href="https://zhuanlan.zhihu.com/p/404453388">https://zhuanlan.zhihu.com/p/404453388</a></li></ul></li><li><p>ROC（receiver operating characteristic curve）</p></li><li><p>混淆矩阵（Confusion matrix）</p></li><li><p>Accuracy</p></li><li><p>Precision</p></li><li><p>Recall</p></li><li><p>F1</p></li><li><p>Classification Report</p></li></ul></li></ul></li><li><p>过拟合与欠拟合</p></li><li><p>模型的泛化与正则化</p></li><li><p>交叉验证</p><ul><li>简单交叉验证</li><li>K折交叉验证</li><li>留P法交叉验证</li><li>其它交叉验证方法</li><li>sklearn调用方法</li></ul></li></ul><h3 id="模型调参"><a href="#模型调参" class="headerlink" title="模型调参"></a>模型调参</h3><ul><li>目标</li><li>参数对模型性能的影响P75</li><li>网格搜索</li><li>随机参数优化</li><li>学习曲线</li><li>验证曲线</li></ul><h2 id="五、特征优化"><a href="#五、特征优化" class="headerlink" title="五、特征优化"></a>五、特征优化</h2><h3 id="合成特征"><a href="#合成特征" class="headerlink" title="合成特征"></a>合成特征</h3><ul><li>将一个特征与其本身或其它特征相乘（特征组合）</li><li>两个特征相除</li><li>对连续特征进行分桶（分箱），以分为多个区间分箱</li></ul><h3 id="特征的简单变换-P93"><a href="#特征的简单变换-P93" class="headerlink" title="特征的简单变换 P93"></a>特征的简单变换 P93</h3><ul><li><p>数值特征的变换和组合</p><ul><li>单独特征列的变换如对数都不适应决策树类算法</li><li>特征的线性组合仅适用决策树算法和基于决策树的集成学习算法，因为树模型不擅长捕获不同特征之间的相关性</li><li>常用的数字特征的变换和组合如下</li></ul></li></ul><p>多项式特征<br>比例特征<br>绝对值<br>max(X1,X2),min(X1,X2),X1 or X2</p><ul><li><p>类别特征与数值特征的组合</p><ul><li>使用oandas的groupby操作可以创造一些有意义的特征</li></ul></li></ul><h3 id="决策树创造新特征"><a href="#决策树创造新特征" class="headerlink" title="决策树创造新特征"></a>决策树创造新特征</h3><h3 id="特征组合"><a href="#特征组合" class="headerlink" title="特征组合"></a>特征组合</h3><ul><li>对非线性规律进行编码</li><li>组合独热矢量</li><li>使用分桶特征列训练模型</li></ul><h3 id="生成许多新的特征之后可以考虑使用PCA进行降维"><a href="#生成许多新的特征之后可以考虑使用PCA进行降维" class="headerlink" title="生成许多新的特征之后可以考虑使用PCA进行降维"></a>生成许多新的特征之后可以考虑使用PCA进行降维</h3><h3 id="特征选择的技巧"><a href="#特征选择的技巧" class="headerlink" title="特征选择的技巧"></a>特征选择的技巧</h3><ul><li><p>特征选择的流程（特征提取是从原有的特征的功能中创造新的特征，而特征选择只返回原有特征中的子集）</p><ul><li>流程图P111</li></ul></li><li><p>特征选择与分类器性能</p></li><li><p>搜索算法</p><ul><li>穷举法</li><li>贪心法</li><li>模拟退火</li><li>基因算法</li><li>邻居搜索</li></ul></li><li><p>特征选择方法</p><ul><li>Filter</li><li>Wrapped</li><li>Embedded</li></ul></li></ul><h2 id="六、模型融合（模型优化）"><a href="#六、模型融合（模型优化）" class="headerlink" title="六、模型融合（模型优化）"></a>六、模型融合（模型优化）</h2><h3 id="可以从哪些方面看模型的优劣和优化"><a href="#可以从哪些方面看模型的优劣和优化" class="headerlink" title="可以从哪些方面看模型的优劣和优化"></a>可以从哪些方面看模型的优劣和优化</h3><ul><li>模型学习曲线(判断模型是否过拟合或者欠拟合并作出相应的调整)</li><li>最模型权重参数进行分析，对于权重绝对值高或低的特征，可以进行更细化的工作，也可以进行特征组合</li><li>进行Bad-Case分析，针对错误的例子确定是否还有地方可以修改挖掘，进行模型融合</li></ul><h3 id="模型学习曲线"><a href="#模型学习曲线" class="headerlink" title="模型学习曲线"></a>模型学习曲线</h3><h3 id="模型融合提升技术"><a href="#模型融合提升技术" class="headerlink" title="模型融合提升技术"></a>模型融合提升技术</h3><ul><li><p>Bagging和随机森林</p></li><li><p>Boosting</p><ul><li>AdaBoost</li><li>提升树</li><li>梯度提升树</li></ul></li></ul><h3 id="预测结果融合策略"><a href="#预测结果融合策略" class="headerlink" title="预测结果融合策略"></a>预测结果融合策略</h3><ul><li><p>Voting</p><ul><li>软投票</li><li>硬投票</li></ul></li><li><p>Averaging和Ranking</p></li><li><p>Blending</p></li><li><p>Stacking</p></li></ul><h3 id="其它提升方法"><a href="#其它提升方法" class="headerlink" title="其它提升方法"></a>其它提升方法</h3><ul><li>通过对权重或者特征重要性的分析，可以找到重要的数据的字段及相关的特征方向，并朝此方向继续细化</li><li>通过Bad-Case分析，找到预测不准确的样本点，通过分析，寻找原因。</li></ul><h2 id="七、代码的规范和技巧"><a href="#七、代码的规范和技巧" class="headerlink" title="七、代码的规范和技巧"></a>七、代码的规范和技巧</h2><h3 id="数据探索代码"><a href="#数据探索代码" class="headerlink" title="数据探索代码"></a>数据探索代码</h3><h3 id="特征工程代码"><a href="#特征工程代码" class="headerlink" title="特征工程代码"></a>特征工程代码</h3><ul><li><p>工具函数</p><ul><li>特征处理函数</li><li>统计特征生成函数</li><li>其它等等</li></ul></li><li><p>特征群生成函数</p><ul><li>每一个特征群生成函数都可以看成一个小型的特征工程包括去重，缺失值处理，特征提取等</li></ul></li><li><p>版本集成函数</p><ul><li>可以对每一个版本都写一个对应的版本函数</li></ul></li><li><p>特征生成函数</p><ul><li><p>特征输出</p><ul><li>对不同版本的特征进行保存</li></ul></li><li><p>特征读取</p><ul><li>读取不同特征版本的训练集，测试集等</li></ul></li></ul></li></ul><h3 id="模型训练，评估，验证，结果代码"><a href="#模型训练，评估，验证，结果代码" class="headerlink" title="模型训练，评估，验证，结果代码"></a>模型训练，评估，验证，结果代码</h3><ul><li>对模型评估，验证，训练，学习曲线等都可以写好函数</li></ul><h3 id="内存管理和加速处理"><a href="#内存管理和加速处理" class="headerlink" title="内存管理和加速处理"></a>内存管理和加速处理</h3><h2 id="八、参考文献"><a href="#八、参考文献" class="headerlink" title="八、参考文献"></a>八、参考文献</h2><p>阿里云天池大赛赛题解析 机器学习篇</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Generation of word vector</title>
      <link href="/2023/05/15/Generation-of-word-vector/"/>
      <url>/2023/05/15/Generation-of-word-vector/</url>
      
        <content type="html"><![CDATA[<h1 id="本文为噜噜猪为咕咕鸟定制"><a href="#本文为噜噜猪为咕咕鸟定制" class="headerlink" title="本文为噜噜猪为咕咕鸟定制"></a>本文为<strong>噜噜猪为咕咕鸟</strong>定制</h1><h2 id="文本的表示方法"><a href="#文本的表示方法" class="headerlink" title="文本的表示方法"></a>文本的表示方法</h2><ol><li>词向量</li><li>词的独热表示(One-hot Encoding)</li><li>词的分布式表示</li><li>词嵌入表示（Word Embedding）</li><li>文本的词袋表示<span id="more"></span></li></ol><h2 id="词嵌入（Word-Embedding）"><a href="#词嵌入（Word-Embedding）" class="headerlink" title="词嵌入（Word Embedding）"></a>词嵌入（Word Embedding）</h2><h3 id="一、静态词向量预训练模型"><a href="#一、静态词向量预训练模型" class="headerlink" title="一、静态词向量预训练模型"></a>一、静态词向量预训练模型</h3><ol><li>前馈神经网络和循环神经网络<br>核心：利用前面的k个词预测下一个词<br>用的前馈神经网络固定用前k个词预测下一个词<br>用的循环神经网络所以可以调节k进行预测下一个词</li><li>Word2vec（相对与前馈神经网络和循环网络可以使用前后文的词信息进行词的预测）<br>Word2vec包括两种模型CBOW(Continuous Bag-of-Words)和Skip-gram<br>CBOW：前后文的词预测中间的词<br>模型的词向量层表示参数为E,将E*ei(ei为词表中第i个词的独热编码)得到词向量，经过隐藏层，输出层的参数表示为E’。模型主要目标就是训练词向量层的参数矩阵E，最后得到的E将是一个词向量矩阵大小为embedding-dim×len(vocab)<br>Skip-gram：使用中间的词预测前后文的词</li><li>GloVe</li></ol><h3 id="二、动态词向量预训练模型"><a href="#二、动态词向量预训练模型" class="headerlink" title="二、动态词向量预训练模型"></a>二、动态词向量预训练模型</h3><p>静态方法得到的一个词向量是基于所使用的语料库，聚合了整个语料库的信息，但是在不同的句子中同一个词表达的意思是不同的而静态方法在同一个语料库训练得到的词向量在不同的句子中的表示是固定的所以说它是静态的方法。<br>动态的方法得到的词向量是随着其上下文的变换而变化的。<br>静态方法是使用一定的语料库进行训练得到的是词向量矩阵进行保存是不变的静态的<br>ELMo<br>模型的编码部分（包括输入表示层以及多层堆叠的LSTM）可以用来计算文本的动态向量表示，最自然的做法是使用最后一层的隐藏层输出作为词的动态向量表示。在ELMo模型中，不同层次的隐藏层向量蕴含了不同层次或粒度的文本信息，例如越接近顶层的LSTM隐藏层表示通常编码了更多的语义信息，不同的下游任务可以使用不同的语义信息。<br>ELMo模型训练完之后保存的是其编码器部分，在下游任务中，将文本经过其编码器得到词向量，静态的模型训练的到的模型参数E为词表在将词才词表中寻找对应的词向量，当然也可以看作将输入经过静态模型的词向量层得到词向量，因为在静态模型的下游任务中经过词向量层就是一个检索的过程，不涉及上下文的学习得到词向量，因为在预训练时词向量层就是一个检索过程，不涉及上下文，循环神经网络是在隐藏层。</p><h3 id="三、Bert和GPT"><a href="#三、Bert和GPT" class="headerlink" title="三、Bert和GPT"></a>三、Bert和GPT</h3><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3><h2 id="名称解释"><a href="#名称解释" class="headerlink" title="名称解释"></a>名称解释</h2><ol><li>词表（Vocabulary）<br>每一个token对应一个索引值，输入层即为每一个token对应的索引值组成的向量。如我爱中国&#x3D;》[2,5,3,8],说明我在词表的索引为2，爱在词表的索引值为5等等。</li><li>词向量层<br>将输入层的每一个整数转化为embedding-dim大小的向量<br>如:当embedding-dim&#x3D;3时[2,5,3,8]&#x3D;&gt; ([2,4,5],[6,7,2],[3,1,0],[0,9,8])</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>github+hexo 搭建个人博客</title>
      <link href="/2023/05/14/github-hexo-builds-a-blog-site/"/>
      <url>/2023/05/14/github-hexo-builds-a-blog-site/</url>
      
        <content type="html"><![CDATA[<h2 id="本文面向对象"><a href="#本文面向对象" class="headerlink" title="本文面向对象"></a>本文面向对象</h2><h1 id="本文仅限天才的咕咕鸟阅读"><a href="#本文仅限天才的咕咕鸟阅读" class="headerlink" title="本文仅限天才的咕咕鸟阅读"></a>本文仅限<strong>天才的咕咕鸟</strong>阅读</h1><span id="more"></span><h2 id="git密钥连接github（做过的可省略）"><a href="#git密钥连接github（做过的可省略）" class="headerlink" title="git密钥连接github（做过的可省略）"></a>git密钥连接github（做过的可省略）</h2><ol start="0"><li>可以先到github主页-&gt;头像-&gt;setting-&gt;SSH and GPG keys查看是否已经设置过<br><img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_10-49-34.png"></li><li>自己选择一个位置新建一个文件夹存放博客和hexo文件在该文件夹中创建一个文件夹命名为hexo，下文中的根目录指的都是hexo目录。</li><li>在根目录右键选择git bash Here打开</li><li>输入以下命令设置git全局配置（name为你github的用户名，email为github的邮箱）<br> <code>git --config global &quot;name&quot;</code><br> <code>git --config global &quot;email&quot;</code></li><li>生成密钥<br> <code>h-keygen -t rsa -C &quot;Email&quot;</code></li><li>查看密钥<br>打开&#x2F;c&#x2F;Users&#x2F;you&#x2F;.ssh&#x2F;id_rsa.pub.文件并复制内容<br>到github主页-&gt;头像-&gt;setting-&gt;SSH and GPG keys点击New SSH将复制内容粘贴到key中，title自己填<br><img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_10-54-44.png"></li><li>查看是否连接成功<br>回到git bash Heres输入<br> <code>ssh -T git@github.com</code><br> 若出现你的用户名则连接成功</li></ol><h2 id="github创建仓库"><a href="#github创建仓库" class="headerlink" title="github创建仓库"></a>github创建仓库</h2><ol><li>与正常的创建相同，唯一不同的是Repository name需要设置为 用户名&#x2F;用户名.github.io</li><li>勾选 Add a README file 即可</li></ol><h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2><ol><li>回到git bash Here输入<br> <code>npm install hexo-cli -g</code></li><li>输入<br> <code>hexo -v</code><br> 查看是否安装成功</li></ol><h2 id="配置hexo"><a href="#配置hexo" class="headerlink" title="配置hexo"></a>配置hexo</h2><ol><li><p>依次输入以下命令<br> <code>hexo init</code><br> <code>npm install</code></p></li><li><p>配置config文件<br> <img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_14-21-57.png"></p></li><li><p>配置github仓库(先执行操作部署，如果不行再执行该步骤)<br> 原因：可能访问时默认的是main分支但是hexo部署到了master分支<br> 目标：对默认访问分支改为master<br> 步骤：<br> a、进入对应仓库-&gt;setting-&gt;General-&gt;修改Default branch<br> <img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_14-28-02.png"><br> b、进入对应仓库-&gt;setting-&gt;Pages-修改branch<br> <img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_14-27-07.png"></p></li></ol><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>再操作前先安装一个插件，根目录进入git Bash Here输入命令<br>    <code>npm i hexo-deployer-git</code></p><ol><li>创建新的博客（markdown文件）<br>根目录进入git Bash Here输入命令<br> <code>hexo new post &quot;title&quot;</code><br> title为博客标题，之后在根目录&#x2F;source&#x2F;_post&#x2F; 下即可看到对应的.md文件，在其中编写博客即可</li><li>生成本地网页(public文件夹)<br>根目录进入git Bash Here输入命令<br> <code>hexo g</code><br> 此时根目录会多一个文件夹public</li><li>将网页部署到github<br>根目录进入git Bash Here输入命令<br> <code>hexo d</code><br> 此时访问你的网站网址（github用户名.github.io）即可查看博客</li><li>清除本地public<br>根目录进入git Bash Here输入命令<br> <code>hexo clean</code><br> 此时目录中的public文件夹被清除</li></ol><p>执行完1，2，3步后若无法查看到写的博客，可能的原因之一是将网页部署到了github的mater分支，可到github上查看，如果是的话，参考配置github仓库小节</p><h2 id="其它问题"><a href="#其它问题" class="headerlink" title="其它问题"></a>其它问题</h2><ol><li>博客图片加载问题<br><a href="https://hexo.io/zh-cn/docs/asset-folders,%E6%B3%A8%E6%84%8F%E8%AF%84%E8%AE%BA%E5%8C%BA%E6%94%B9">https://hexo.io/zh-cn/docs/asset-folders,注意评论区改</a> \node_modules\hexo-asset-image\index.js 的代码<br><img src="/2023/05/14/github-hexo-builds-a-blog-site/Snipaste_2023-05-14_16-51-23.png"></li><li>博客网站主题<br><a href="https://molunerfinn.com/hexo-theme-melody-doc/#features">https://molunerfinn.com/hexo-theme-melody-doc/#features</a></li><li>更多操作可以看hexo官网文档<br><a href="https://hexo.io/zh-cn/docs/">https://hexo.io/zh-cn/docs/</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 网站 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
